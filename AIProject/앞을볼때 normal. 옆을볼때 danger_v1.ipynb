{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86fa3cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\project\\deep\\lib\\site-packages (4.7.0.68)\n",
      "Requirement already satisfied: dlib in c:\\project\\deep\\lib\\site-packages (19.24.6)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\project\\deep\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\project\\deep\\lib\\site-packages\\radam-0.0.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python dlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76b0404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\project\\deep\\lib\\site-packages (4.7.0.68)\n",
      "Requirement already satisfied: dlib in c:\\project\\deep\\lib\\site-packages (19.24.6)\n",
      "Requirement already satisfied: imutils in c:\\project\\deep\\lib\\site-packages (0.5.4)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\project\\deep\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\project\\deep\\lib\\site-packages\\radam-0.0.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python dlib imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ee5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 카메라 행렬 설정\n",
    "카메라 행렬(camera_matrix)의 값이 실제 카메라의 초점 거리와 센서 크기에 맞지 않으면 정확한 포즈 추정이 어렵습니다. 현재는 화면의 가로 크기를 초점 거리로 사용하고 있지만, 실제 카메라의 매개변수를 사용해야 합니다.\n",
    "\n",
    "2. 왜곡 계수\n",
    "왜곡 계수(dist_coeffs)를 0으로 설정했는데, 실제 카메라의 왜곡 계수를 고려해야 할 수 있습니다. 실제 왜곡 계수를 모르더라도, 0으로 설정하는 것은 기본값입니다.\n",
    "\n",
    "3. 오일러 각도 추출\n",
    "cv2.decomposeProjectionMatrix를 사용하여 오일러 각도를 추출하는 방법은 좀 복잡할 수 있습니다. 오일러 각도를 직접 계산하거나 다른 방법으로 포즈를 추정할 수 있습니다.\n",
    "\n",
    "4. PnP 알고리즘의 정확성\n",
    "cv2.solvePnP의 결과가 정확하지 않을 수 있습니다. 모델 포인트와 이미지 포인트의 매칭이 잘못되었을 수 있습니다.\n",
    "\n",
    "아래는 개선된 코드로, 카메라 매트릭스와 왜곡 계수를 좀 더 정확하게 설정하고, 회전 벡터에서 직접 피치와 요 각도를 추정하는 방법을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b62c9f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\project\\deep\\lib\\site-packages (2.3.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\project\\deep\\lib\\site-packages (0.18.1+cu118)\n",
      "Requirement already satisfied: transformers in c:\\project\\deep\\lib\\site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in c:\\project\\deep\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\project\\deep\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\project\\deep\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\project\\deep\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\project\\deep\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\project\\deep\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\project\\deep\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\project\\deep\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\project\\deep\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\project\\deep\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\project\\deep\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\project\\deep\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\project\\deep\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\project\\deep\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\project\\deep\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\project\\deep\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\project\\deep\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\project\\deep\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\project\\deep\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: colorama in c:\\project\\deep\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\project\\deep\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\project\\deep\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\project\\deep\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\project\\deep\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\project\\deep\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\project\\deep\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\project\\deep\\lib\\site-packages\\radam-0.0.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d287a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\project\\deep\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# MediaPipe Hands 모듈 초기화\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def is_palm_facing_camera(hand_landmarks):\n",
    "    \"\"\"손바닥이 카메라를 향하고 있는지 확인하는 함수\"\"\"\n",
    "    wrist = np.array([hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x,\n",
    "                      hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y,\n",
    "                      hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].z])\n",
    "    \n",
    "    index_finger_tip = np.array([hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x,\n",
    "                                 hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y,\n",
    "                                 hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].z])\n",
    "    \n",
    "    thumb_tip = np.array([hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x,\n",
    "                          hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y,\n",
    "                          hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].z])\n",
    "    \n",
    "    # 손목과 손끝 사이의 벡터를 계산\n",
    "    wrist_to_index = index_finger_tip - wrist\n",
    "    wrist_to_thumb = thumb_tip - wrist\n",
    "    \n",
    "    # 벡터의 내적을 사용하여 손바닥의 방향 판단\n",
    "    palm_normal_vector = np.cross(wrist_to_index, wrist_to_thumb)\n",
    "    \n",
    "    # 벡터의 z값을 확인 (손바닥이 카메라를 향할 때 z값이 양수임)\n",
    "    return palm_normal_vector[2] > 0\n",
    "\n",
    "# 카메라 캡처\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # BGR 이미지를 RGB로 변환\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # MediaPipe로 손 랜드마크 검출\n",
    "    result = hands.process(rgb_frame)\n",
    "\n",
    "    hand_detected = False\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            hand_detected = True\n",
    "\n",
    "            # 손바닥이 카메라를 향하고 있는지 판단\n",
    "            if is_palm_facing_camera(hand_landmarks):\n",
    "                color = (0, 255, 0)  # 초록색 (정상)\n",
    "                status = \"NORMAL\"\n",
    "            else:\n",
    "                color = (0, 0, 255)  # 빨간색 (비정상)\n",
    "                status = \"DANGER\"\n",
    "\n",
    "            # 손 랜드마크를 이미지에 그림\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=2))\n",
    "\n",
    "            # 바운딩 박스 그리기\n",
    "            h, w, c = frame.shape\n",
    "            x_min = min([landmark.x for landmark in hand_landmarks.landmark]) * w\n",
    "            y_min = min([landmark.y for landmark in hand_landmarks.landmark]) * h\n",
    "            x_max = max([landmark.x for landmark in hand_landmarks.landmark]) * w\n",
    "            y_max = max([landmark.y for landmark in hand_landmarks.landmark]) * h\n",
    "            cv2.rectangle(frame, (int(x_min), int(y_min)), (int(x_max), int(y_max)), color, 2)\n",
    "\n",
    "            # 상태 텍스트 표시\n",
    "            cv2.putText(frame, status, (int(x_min), int(y_min) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    if not hand_detected:\n",
    "        # 손이 검출되지 않은 경우 메시지 표시하지 않음\n",
    "        pass\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4ccabd",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\solvepnp.cpp:840: error: (-215:Assertion failed) ( (npoints >= 4) || (npoints == 3 && flags == SOLVEPNP_ITERATIVE && useExtrinsicGuess) || (npoints >= 3 && flags == SOLVEPNP_SQPNP) ) && npoints == std::max(ipoints.checkVector(2, CV_32F), ipoints.checkVector(2, CV_64F)) in function 'cv::solvePnPGeneric'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# SolvePnP를 사용하여 회전 벡터와 변환 벡터 계산\u001b[39;00m\n\u001b[0;32m     74\u001b[0m dist_coeffs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# 카메라 왜곡 계수, 여기서는 0으로 가정\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m (success, rotation_vector, translation_vector) \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolvePnP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_coeffs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOLVEPNP_ITERATIVE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_face_facing_camera(rotation_vector):\n\u001b[0;32m     78\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# 초록색 (정상)\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\solvepnp.cpp:840: error: (-215:Assertion failed) ( (npoints >= 4) || (npoints == 3 && flags == SOLVEPNP_ITERATIVE && useExtrinsicGuess) || (npoints >= 3 && flags == SOLVEPNP_SQPNP) ) && npoints == std::max(ipoints.checkVector(2, CV_32F), ipoints.checkVector(2, CV_64F)) in function 'cv::solvePnPGeneric'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 얼굴 검출기 로드 (OpenCV DNN 모듈)\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    \"deploy.prototxt.txt\",  # 네트워크 아키텍처 파일\n",
    "    \"res10_300x300_ssd_iter_140000.caffemodel\"  # 훈련된 모델 파일\n",
    ")\n",
    "\n",
    "# 3D 모델 포인트\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),             # 코끝\n",
    "    (0.0, -330.0, -65.0),        # 턱\n",
    "    (-225.0, 170.0, -135.0),     # 왼쪽 눈 왼쪽 구석\n",
    "    (225.0, 170.0, -135.0),      # 오른쪽 눈 오른쪽 구석\n",
    "    (-150.0, -150.0, -125.0),    # 왼쪽 입 구석\n",
    "    (150.0, -150.0, -125.0)      # 오른쪽 입 구석\n",
    "])\n",
    "\n",
    "def is_face_facing_camera(rotation_vector):\n",
    "    \"\"\"얼굴이 카메라를 향하고 있는지 확인하는 함수\"\"\"\n",
    "    # 회전 벡터를 회전 행렬로 변환\n",
    "    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "    \n",
    "    # 회전 행렬을 오일러 각도로 변환\n",
    "    pose_mat = np.hstack((rotation_matrix, np.array([[0], [0], [0]])))\n",
    "    _, _, _, _, _, _, euler_angles = cv2.decomposeProjectionMatrix(pose_mat)\n",
    "    \n",
    "    pitch, yaw, roll = [math.radians(_) for _ in euler_angles]\n",
    "\n",
    "    # 얼굴이 정면을 향하고 있는지 확인 (yaw와 pitch가 일정 범위 내에 있는지)\n",
    "    return abs(yaw) < 10 and abs(pitch) < 10\n",
    "\n",
    "# 카메라 캡처\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # 카메라 행렬 정의\n",
    "    focal_length = width\n",
    "    center = (width / 2, height / 2)\n",
    "    camera_matrix = np.array(\n",
    "        [[focal_length, 0, center[0]],\n",
    "         [0, focal_length, center[1]],\n",
    "         [0, 0, 1]], dtype=\"double\"\n",
    "    )\n",
    "\n",
    "    # 이미지 전처리\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    face_detected = False\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.7:\n",
    "            face_detected = True\n",
    "            box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "            (x_min, y_min, x_max, y_max) = box.astype(\"int\")\n",
    "\n",
    "            # 2D 이미지 포인트 추출 (단순히 중심에 있는 점을 사용하는 예시)\n",
    "            image_points = np.array([\n",
    "                ((x_min + x_max) / 2, (y_min + y_max) / 2),     # 중심\n",
    "            ], dtype=\"double\")\n",
    "\n",
    "            # SolvePnP를 사용하여 회전 벡터와 변환 벡터 계산\n",
    "            dist_coeffs = np.zeros((4, 1))  # 카메라 왜곡 계수, 여기서는 0으로 가정\n",
    "            (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "            if is_face_facing_camera(rotation_vector):\n",
    "                color = (0, 255, 0)  # 초록색 (정상)\n",
    "                status = \"NORMAL\"\n",
    "            else:\n",
    "                color = (0, 0, 255)  # 빨간색 (비정상)\n",
    "                status = \"DANGER\"\n",
    "\n",
    "            # 얼굴 주변에 bounding box 그리기\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "            cv2.putText(frame, status, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "            # 얼굴 방향 정보 표시\n",
    "            cv2.putText(frame, f\"Pitch: {int(math.degrees(pitch))}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Yaw: {int(math.degrees(yaw))}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Roll: {int(math.degrees(roll))}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    if not face_detected:\n",
    "        # 얼굴이 검출되지 않은 경우 메시지 표시하지 않음\n",
    "        pass\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a0da01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2460\\359622340.py:97: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.putText(frame, f\"Pitch: {int(math.degrees(pitch))}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2460\\359622340.py:98: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.putText(frame, f\"Yaw: {int(math.degrees(yaw))}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2460\\359622340.py:99: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.putText(frame, f\"Roll: {int(math.degrees(roll))}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 얼굴 검출기 로드 (OpenCV DNN 모듈)\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    \"deploy.prototxt.txt\",  # 네트워크 아키텍처 파일\n",
    "    \"res10_300x300_ssd_iter_140000.caffemodel\"  # 훈련된 모델 파일\n",
    ")\n",
    "\n",
    "# 3D 모델 포인트\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),             # 코끝\n",
    "    (0.0, -330.0, -65.0),        # 턱\n",
    "    (-225.0, 170.0, -135.0),     # 왼쪽 눈 왼쪽 구석\n",
    "    (225.0, 170.0, -135.0),      # 오른쪽 눈 오른쪽 구석\n",
    "    (-150.0, -150.0, -125.0),    # 왼쪽 입 구석\n",
    "    (150.0, -150.0, -125.0)      # 오른쪽 입 구석\n",
    "])\n",
    "\n",
    "def get_euler_angles(rotation_vector):\n",
    "    \"\"\"회전 벡터를 오일러 각도로 변환\"\"\"\n",
    "    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "    pose_mat = np.hstack((rotation_matrix, np.array([[0], [0], [0]])))\n",
    "    _, _, _, _, _, _, euler_angles = cv2.decomposeProjectionMatrix(pose_mat)\n",
    "    return np.radians(euler_angles)\n",
    "\n",
    "def is_face_facing_camera(rotation_vector):\n",
    "    \"\"\"얼굴이 카메라를 향하고 있는지 확인하는 함수\"\"\"\n",
    "    euler_angles = get_euler_angles(rotation_vector)\n",
    "    pitch, yaw, roll = euler_angles[0], euler_angles[1], euler_angles[2]\n",
    "\n",
    "    # 얼굴이 정면을 향하고 있는지 확인 (yaw와 pitch가 일정 범위 내에 있는지)\n",
    "    return abs(yaw) < 10 and abs(pitch) < 10, pitch, yaw, roll\n",
    "\n",
    "# 카메라 캡처\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # 카메라 행렬 정의\n",
    "    focal_length = width\n",
    "    center = (width / 2, height / 2)\n",
    "    camera_matrix = np.array(\n",
    "        [[focal_length, 0, center[0]],\n",
    "         [0, focal_length, center[1]],\n",
    "         [0, 0, 1]], dtype=\"double\"\n",
    "    )\n",
    "\n",
    "    # 이미지 전처리\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    face_detected = False\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.7:\n",
    "            face_detected = True\n",
    "            box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "            (x_min, y_min, x_max, y_max) = box.astype(\"int\")\n",
    "\n",
    "            # 2D 이미지 포인트 추출 (랜드마크 기반으로 업데이트 필요)\n",
    "            image_points = np.array([\n",
    "                (x_min, y_min),    # 코끝\n",
    "                (x_min, y_max),    # 턱\n",
    "                (x_min + (x_max - x_min) * 0.2, y_min + (y_max - y_min) * 0.2),  # 왼쪽 눈\n",
    "                (x_min + (x_max - x_min) * 0.8, y_min + (y_max - y_min) * 0.2),  # 오른쪽 눈\n",
    "                (x_min + (x_max - x_min) * 0.2, y_max - (y_max - y_min) * 0.2),  # 왼쪽 입\n",
    "                (x_min + (x_max - x_min) * 0.8, y_max - (y_max - y_min) * 0.2)   # 오른쪽 입\n",
    "            ], dtype=\"double\")\n",
    "\n",
    "            # SolvePnP를 사용하여 회전 벡터와 변환 벡터 계산\n",
    "            dist_coeffs = np.zeros((4, 1))  # 카메라 왜곡 계수, 여기서는 0으로 가정\n",
    "            (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "            if success:\n",
    "                face_facing_camera, pitch, yaw, roll = is_face_facing_camera(rotation_vector)\n",
    "                if face_facing_camera:\n",
    "                    color = (0, 255, 0)  # 초록색 (정상)\n",
    "                    status = \"NORMAL\"\n",
    "                else:\n",
    "                    color = (0, 0, 255)  # 빨간색 (비정상)\n",
    "                    status = \"DANGER\"\n",
    "\n",
    "                # 얼굴 주변에 bounding box 그리기\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "                cv2.putText(frame, status, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "                # 얼굴 방향 정보 표시\n",
    "                cv2.putText(frame, f\"Pitch: {int(math.degrees(pitch))}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Yaw: {int(math.degrees(yaw))}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Roll: {int(math.degrees(roll))}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    if not face_detected:\n",
    "        # 얼굴이 검출되지 않은 경우 메시지 표시하지 않음\n",
    "        pass\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d575a62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2460\\913725031.py:99: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.putText(frame, f\"Pitch: {int(math.degrees(pitch))}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2460\\913725031.py:100: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.putText(frame, f\"Yaw: {int(math.degrees(yaw))}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2460\\913725031.py:101: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.putText(frame, f\"Roll: {int(math.degrees(roll))}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 얼굴 검출기 로드 (OpenCV DNN 모듈)\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    \"deploy.prototxt.txt\",  # 네트워크 아키텍처 파일\n",
    "    \"res10_300x300_ssd_iter_140000.caffemodel\"  # 훈련된 모델 파일\n",
    ")\n",
    "\n",
    "# 3D 모델 포인트\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),             # 코끝\n",
    "    (0.0, -330.0, -65.0),        # 턱\n",
    "    (-225.0, 170.0, -135.0),     # 왼쪽 눈 왼쪽 구석\n",
    "    (225.0, 170.0, -135.0),      # 오른쪽 눈 오른쪽 구석\n",
    "    (-150.0, -150.0, -125.0),    # 왼쪽 입 구석\n",
    "    (150.0, -150.0, -125.0)      # 오른쪽 입 구석\n",
    "])\n",
    "\n",
    "def get_euler_angles(rotation_vector):\n",
    "    \"\"\"회전 벡터를 오일러 각도로 변환\"\"\"\n",
    "    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "    pose_mat = np.hstack((rotation_matrix, np.array([[0], [0], [0]])))\n",
    "    _, _, _, _, _, _, euler_angles = cv2.decomposeProjectionMatrix(pose_mat)\n",
    "    return np.radians(euler_angles)\n",
    "\n",
    "def is_face_facing_camera(rotation_vector):\n",
    "    \"\"\"얼굴이 카메라를 향하고 있는지 확인하는 함수\"\"\"\n",
    "    euler_angles = get_euler_angles(rotation_vector)\n",
    "    pitch, yaw, roll = euler_angles[0], euler_angles[1], euler_angles[2]\n",
    "\n",
    "    # 얼굴이 정면을 향하고 있는지 확인 (yaw와 pitch가 일정 범위 내에 있는지)\n",
    "    return abs(yaw) < 10 and abs(pitch) < 10, pitch, yaw, roll\n",
    "\n",
    "# 카메라 캡처\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # 카메라 행렬 정의\n",
    "    focal_length = width\n",
    "    center = (width / 2, height / 2)\n",
    "    camera_matrix = np.array(\n",
    "        [[focal_length, 0, center[0]],\n",
    "         [0, focal_length, center[1]],\n",
    "         [0, 0, 1]], dtype=\"double\"\n",
    "    )\n",
    "\n",
    "    # 이미지 전처리\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    face_detected = False\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.7:\n",
    "            face_detected = True\n",
    "            box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "            (x_min, y_min, x_max, y_max) = box.astype(\"int\")\n",
    "\n",
    "            # 2D 이미지 포인트 추출 (랜드마크 기반으로 업데이트 필요)\n",
    "            image_points = np.array([\n",
    "                (x_min + (x_max - x_min) * 0.5, y_min + (y_max - y_min) * 0.5),  # 코끝\n",
    "                (x_min, y_max),  # 턱\n",
    "                (x_min + (x_max - x_min) * 0.2, y_min + (y_max - y_min) * 0.2),  # 왼쪽 눈\n",
    "                (x_min + (x_max - x_min) * 0.8, y_min + (y_max - y_min) * 0.2),  # 오른쪽 눈\n",
    "                (x_min + (x_max - x_min) * 0.2, y_max - (y_max - y_min) * 0.2),  # 왼쪽 입\n",
    "                (x_min + (x_max - x_min) * 0.8, y_max - (y_max - y_min) * 0.2)   # 오른쪽 입\n",
    "            ], dtype=\"double\")\n",
    "\n",
    "            # SolvePnP를 사용하여 회전 벡터와 변환 벡터 계산\n",
    "            dist_coeffs = np.zeros((4, 1))  # 카메라 왜곡 계수, 여기서는 0으로 가정\n",
    "            (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "            if success:\n",
    "                face_facing_camera, pitch, yaw, roll = is_face_facing_camera(rotation_vector)\n",
    "                \n",
    "                # 얼굴이 정면을 향할 때와 약간 틀릴 때 조건\n",
    "                if face_facing_camera:\n",
    "                    color = (0, 255, 0)  # 초록색 (정상)\n",
    "                    status = \"NORMAL\"\n",
    "                else:\n",
    "                    color = (0, 0, 255)  # 빨간색 (비정상)\n",
    "                    status = \"DANGER\"\n",
    "\n",
    "                # 얼굴 주변에 bounding box 그리기\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "                cv2.putText(frame, status, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "                # 얼굴 방향 정보 표시\n",
    "                cv2.putText(frame, f\"Pitch: {int(math.degrees(pitch))}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Yaw: {int(math.degrees(yaw))}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Roll: {int(math.degrees(roll))}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    if not face_detected:\n",
    "        # 얼굴이 검출되지 않은 경우 메시지 표시하지 않음\n",
    "        pass\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a1a9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2460\\209947352.py:107: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.putText(frame, f\"Pitch: {int(math.degrees(pitch))}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2460\\209947352.py:108: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.putText(frame, f\"Yaw: {int(math.degrees(yaw))}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2460\\209947352.py:109: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.putText(frame, f\"Roll: {int(math.degrees(roll))}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 얼굴 검출기 로드 (OpenCV DNN 모듈)\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    \"deploy.prototxt.txt\",  # 네트워크 아키텍처 파일\n",
    "    \"res10_300x300_ssd_iter_140000.caffemodel\"  # 훈련된 모델 파일\n",
    ")\n",
    "\n",
    "# 3D 모델 포인트\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),             # 코끝\n",
    "    (0.0, -330.0, -65.0),        # 턱\n",
    "    (-225.0, 170.0, -135.0),     # 왼쪽 눈 왼쪽 구석\n",
    "    (225.0, 170.0, -135.0),      # 오른쪽 눈 오른쪽 구석\n",
    "    (-150.0, -150.0, -125.0),    # 왼쪽 입 구석\n",
    "    (150.0, -150.0, -125.0)      # 오른쪽 입 구석\n",
    "])\n",
    "\n",
    "def get_euler_angles(rotation_vector):\n",
    "    \"\"\"회전 벡터를 오일러 각도로 변환\"\"\"\n",
    "    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "    pose_mat = np.hstack((rotation_matrix, np.array([[0], [0], [0]])))\n",
    "    _, _, _, _, _, _, euler_angles = cv2.decomposeProjectionMatrix(pose_mat)\n",
    "    return np.radians(euler_angles)\n",
    "\n",
    "def is_face_facing_camera(rotation_vector):\n",
    "    \"\"\"얼굴이 카메라를 향하고 있는지 확인하는 함수\"\"\"\n",
    "    euler_angles = get_euler_angles(rotation_vector)\n",
    "    pitch, yaw, roll = euler_angles[0], euler_angles[1], euler_angles[2]\n",
    "\n",
    "    # 각도 범위를 더 엄격하게 조정\n",
    "    yaw_threshold = np.radians(5)  # 5도\n",
    "    pitch_threshold = np.radians(5)  # 5도\n",
    "    roll_threshold = np.radians(5)  # 5도\n",
    "\n",
    "    is_facing = (abs(yaw) < yaw_threshold and \n",
    "                 abs(pitch) < pitch_threshold and \n",
    "                 abs(roll) < roll_threshold)\n",
    "\n",
    "    return is_facing, pitch, yaw, roll\n",
    "\n",
    "# 카메라 캡처\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # 카메라 행렬 정의\n",
    "    focal_length = width\n",
    "    center = (width / 2, height / 2)\n",
    "    camera_matrix = np.array(\n",
    "        [[focal_length, 0, center[0]],\n",
    "         [0, focal_length, center[1]],\n",
    "         [0, 0, 1]], dtype=\"double\"\n",
    "    )\n",
    "\n",
    "    # 이미지 전처리\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    face_detected = False\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.7:\n",
    "            face_detected = True\n",
    "            box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "            (x_min, y_min, x_max, y_max) = box.astype(\"int\")\n",
    "\n",
    "            # 2D 이미지 포인트 추출 (랜드마크 기반으로 업데이트 필요)\n",
    "            image_points = np.array([\n",
    "                (x_min + (x_max - x_min) * 0.5, y_min + (y_max - y_min) * 0.5),  # 코끝\n",
    "                (x_min, y_max),  # 턱\n",
    "                (x_min + (x_max - x_min) * 0.2, y_min + (y_max - y_min) * 0.2),  # 왼쪽 눈\n",
    "                (x_min + (x_max - x_min) * 0.8, y_min + (y_max - y_min) * 0.2),  # 오른쪽 눈\n",
    "                (x_min + (x_max - x_min) * 0.2, y_max - (y_max - y_min) * 0.2),  # 왼쪽 입\n",
    "                (x_min + (x_max - x_min) * 0.8, y_max - (y_max - y_min) * 0.2)   # 오른쪽 입\n",
    "            ], dtype=\"double\")\n",
    "\n",
    "            # SolvePnP를 사용하여 회전 벡터와 변환 벡터 계산\n",
    "            dist_coeffs = np.zeros((4, 1))  # 카메라 왜곡 계수, 여기서는 0으로 가정\n",
    "            (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "            if success:\n",
    "                face_facing_camera, pitch, yaw, roll = is_face_facing_camera(rotation_vector)\n",
    "                \n",
    "                # 상태 판단 로직 수정\n",
    "                if face_facing_camera:\n",
    "                    color = (0, 255, 0)  # 초록색 (정상)\n",
    "                    status = \"NORMAL\"\n",
    "                else:\n",
    "                    color = (0, 0, 255)  # 빨간색 (비정상)\n",
    "                    status = \"DANGER\"\n",
    "\n",
    "                # 얼굴 주변에 bounding box 그리기\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "                cv2.putText(frame, status, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "                # 얼굴 방향 정보 표시\n",
    "                cv2.putText(frame, f\"Pitch: {int(math.degrees(pitch))}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Yaw: {int(math.degrees(yaw))}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Roll: {int(math.degrees(roll))}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    if not face_detected:\n",
    "        # 얼굴이 검출되지 않은 경우 메시지 표시하지 않음\n",
    "        pass\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ff46226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2460\\209947352.py:107: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.putText(frame, f\"Pitch: {int(math.degrees(pitch))}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2460\\209947352.py:108: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.putText(frame, f\"Yaw: {int(math.degrees(yaw))}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2460\\209947352.py:109: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.putText(frame, f\"Roll: {int(math.degrees(roll))}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 얼굴 검출기 로드 (OpenCV DNN 모듈)\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    \"deploy.prototxt.txt\",  # 네트워크 아키텍처 파일\n",
    "    \"res10_300x300_ssd_iter_140000.caffemodel\"  # 훈련된 모델 파일\n",
    ")\n",
    "\n",
    "# 3D 모델 포인트\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),             # 코끝\n",
    "    (0.0, -330.0, -65.0),        # 턱\n",
    "    (-225.0, 170.0, -135.0),     # 왼쪽 눈 왼쪽 구석\n",
    "    (225.0, 170.0, -135.0),      # 오른쪽 눈 오른쪽 구석\n",
    "    (-150.0, -150.0, -125.0),    # 왼쪽 입 구석\n",
    "    (150.0, -150.0, -125.0)      # 오른쪽 입 구석\n",
    "])\n",
    "\n",
    "def get_euler_angles(rotation_vector):\n",
    "    \"\"\"회전 벡터를 오일러 각도로 변환\"\"\"\n",
    "    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "    pose_mat = np.hstack((rotation_matrix, np.array([[0], [0], [0]])))\n",
    "    _, _, _, _, _, _, euler_angles = cv2.decomposeProjectionMatrix(pose_mat)\n",
    "    return np.radians(euler_angles)\n",
    "\n",
    "def is_face_facing_camera(rotation_vector):\n",
    "    \"\"\"얼굴이 카메라를 향하고 있는지 확인하는 함수\"\"\"\n",
    "    euler_angles = get_euler_angles(rotation_vector)\n",
    "    pitch, yaw, roll = euler_angles[0], euler_angles[1], euler_angles[2]\n",
    "\n",
    "    # 각도 범위를 더 엄격하게 조정\n",
    "    yaw_threshold = np.radians(5)  # 5도\n",
    "    pitch_threshold = np.radians(5)  # 5도\n",
    "    roll_threshold = np.radians(5)  # 5도\n",
    "\n",
    "    is_facing = (abs(yaw) < yaw_threshold and \n",
    "                 abs(pitch) < pitch_threshold and \n",
    "                 abs(roll) < roll_threshold)\n",
    "\n",
    "    return is_facing, pitch, yaw, roll\n",
    "\n",
    "# 카메라 캡처\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # 카메라 행렬 정의\n",
    "    focal_length = width\n",
    "    center = (width / 2, height / 2)\n",
    "    camera_matrix = np.array(\n",
    "        [[focal_length, 0, center[0]],\n",
    "         [0, focal_length, center[1]],\n",
    "         [0, 0, 1]], dtype=\"double\"\n",
    "    )\n",
    "\n",
    "    # 이미지 전처리\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    face_detected = False\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.7:\n",
    "            face_detected = True\n",
    "            box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "            (x_min, y_min, x_max, y_max) = box.astype(\"int\")\n",
    "\n",
    "            # 2D 이미지 포인트 추출 (랜드마크 기반으로 업데이트 필요)\n",
    "            image_points = np.array([\n",
    "                (x_min + (x_max - x_min) * 0.5, y_min + (y_max - y_min) * 0.5),  # 코끝\n",
    "                (x_min, y_max),  # 턱\n",
    "                (x_min + (x_max - x_min) * 0.2, y_min + (y_max - y_min) * 0.2),  # 왼쪽 눈\n",
    "                (x_min + (x_max - x_min) * 0.8, y_min + (y_max - y_min) * 0.2),  # 오른쪽 눈\n",
    "                (x_min + (x_max - x_min) * 0.2, y_max - (y_max - y_min) * 0.2),  # 왼쪽 입\n",
    "                (x_min + (x_max - x_min) * 0.8, y_max - (y_max - y_min) * 0.2)   # 오른쪽 입\n",
    "            ], dtype=\"double\")\n",
    "\n",
    "            # SolvePnP를 사용하여 회전 벡터와 변환 벡터 계산\n",
    "            dist_coeffs = np.zeros((4, 1))  # 카메라 왜곡 계수, 여기서는 0으로 가정\n",
    "            (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "            if success:\n",
    "                face_facing_camera, pitch, yaw, roll = is_face_facing_camera(rotation_vector)\n",
    "                \n",
    "                # 상태 판단 로직 수정\n",
    "                if face_facing_camera:\n",
    "                    color = (0, 255, 0)  # 초록색 (정상)\n",
    "                    status = \"NORMAL\"\n",
    "                else:\n",
    "                    color = (0, 0, 255)  # 빨간색 (비정상)\n",
    "                    status = \"DANGER\"\n",
    "\n",
    "                # 얼굴 주변에 bounding box 그리기\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "                cv2.putText(frame, status, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "                # 얼굴 방향 정보 표시\n",
    "                cv2.putText(frame, f\"Pitch: {int(math.degrees(pitch))}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Yaw: {int(math.degrees(yaw))}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Roll: {int(math.degrees(roll))}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    if not face_detected:\n",
    "        # 얼굴이 검출되지 않은 경우 메시지 표시하지 않음\n",
    "        pass\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f9db814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2460\\3176102665.py:25: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return [math.radians(angle) for angle in euler_angles]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'HOTERSHEY_SIMPLEX'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 107\u001b[0m\n\u001b[0;32m    105\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPitch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39mdegrees(pitch))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.7\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    106\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYaw: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39mdegrees(yaw))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m60\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.7\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoll: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39mdegrees(roll))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m90\u001b[39m), \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHOTERSHEY_SIMPLEX\u001b[49m, \u001b[38;5;241m0.7\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    109\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'HOTERSHEY_SIMPLEX'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 얼굴 검출기 로드 (OpenCV DNN 모듈)\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    \"deploy.prototxt.txt\",\n",
    "    \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    ")\n",
    "\n",
    "# 3D 모델 포인트\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),             # 코끝\n",
    "    (0.0, -330.0, -65.0),        # 턱\n",
    "    (-225.0, 170.0, -135.0),     # 왼쪽 눈 왼쪽 구석\n",
    "    (225.0, 170.0, -135.0),      # 오른쪽 눈 오른쪽 구석\n",
    "    (-150.0, -150.0, -125.0),    # 왼쪽 입 구석\n",
    "    (150.0, -150.0, -125.0)      # 오른쪽 입 구석\n",
    "])\n",
    "\n",
    "def get_euler_angles(rotation_vector):\n",
    "    \"\"\"회전 벡터를 오일러 각도로 변환\"\"\"\n",
    "    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "    euler_angles = cv2.decomposeProjectionMatrix(np.hstack((rotation_matrix, np.zeros((3, 1)))))[6]\n",
    "    return [math.radians(angle) for angle in euler_angles]\n",
    "\n",
    "def is_face_facing_camera(euler_angles):\n",
    "    \"\"\"얼굴이 카메라를 향하고 있는지 확인하는 함수\"\"\"\n",
    "    pitch, yaw, roll = euler_angles\n",
    "\n",
    "    # 각도 범위 조정 (단위: 라디안)\n",
    "    yaw_threshold = math.radians(20)\n",
    "    pitch_threshold = math.radians(20)\n",
    "    roll_threshold = math.radians(20)\n",
    "\n",
    "    is_facing = (abs(yaw) < yaw_threshold and \n",
    "                 abs(pitch) < pitch_threshold and \n",
    "                 abs(roll) < roll_threshold)\n",
    "\n",
    "    return is_facing, pitch, yaw, roll\n",
    "\n",
    "# 카메라 캡처\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # 카메라 행렬 정의\n",
    "    focal_length = width\n",
    "    center = (width / 2, height / 2)\n",
    "    camera_matrix = np.array(\n",
    "        [[focal_length, 0, center[0]],\n",
    "         [0, focal_length, center[1]],\n",
    "         [0, 0, 1]], dtype=\"double\"\n",
    "    )\n",
    "\n",
    "    # 이미지 전처리\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    face_detected = False\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.7:\n",
    "            face_detected = True\n",
    "            box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "            (x_min, y_min, x_max, y_max) = box.astype(\"int\")\n",
    "\n",
    "            # 2D 이미지 포인트 추출\n",
    "            image_points = np.array([\n",
    "                ((x_min + x_max) // 2, (y_min + y_max) // 2),  # 코끝\n",
    "                ((x_min + x_max) // 2, y_max),                 # 턱\n",
    "                (x_min, (y_min + y_max) // 2),                 # 왼쪽 눈\n",
    "                (x_max, (y_min + y_max) // 2),                 # 오른쪽 눈\n",
    "                (x_min, y_max - (y_max - y_min) // 3),         # 왼쪽 입\n",
    "                (x_max, y_max - (y_max - y_min) // 3)          # 오른쪽 입\n",
    "            ], dtype=\"double\")\n",
    "\n",
    "            # SolvePnP를 사용하여 회전 벡터와 변환 벡터 계산\n",
    "            dist_coeffs = np.zeros((4, 1))  # 카메라 왜곡 계수, 여기서는 0으로 가정\n",
    "            (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "            if success:\n",
    "                euler_angles = get_euler_angles(rotation_vector)\n",
    "                face_facing_camera, pitch, yaw, roll = is_face_facing_camera(euler_angles)\n",
    "                \n",
    "                if face_facing_camera:\n",
    "                    color = (0, 255, 0)  # 초록색 (정상)\n",
    "                    status = \"NORMAL\"\n",
    "                else:\n",
    "                    color = (0, 0, 255)  # 빨간색 (비정상)\n",
    "                    status = \"DANGER\"\n",
    "\n",
    "                # 얼굴 주변에 bounding box 그리기\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "                cv2.putText(frame, status, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "                # 얼굴 방향 정보 표시\n",
    "                cv2.putText(frame, f\"Pitch: {int(math.degrees(pitch))}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Yaw: {int(math.degrees(yaw))}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Roll: {int(math.degrees(roll))}\", (10, 90), cv2.HOTERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91034497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_48260\\2566325854.py:25: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return [math.radians(angle) for angle in euler_angles]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 얼굴 검출기 로드 (OpenCV DNN 모듈)\n",
    "net = cv2.dnn.readNetFromCaffe(\n",
    "    \"deploy.prototxt.txt\",\n",
    "    \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    ")\n",
    "\n",
    "# 3D 모델 포인트\n",
    "model_points = np.array([\n",
    "    (0.0, 0.0, 0.0),             # 코끝\n",
    "    (0.0, -330.0, -65.0),        # 턱\n",
    "    (-225.0, 170.0, -135.0),     # 왼쪽 눈 왼쪽 구석\n",
    "    (225.0, 170.0, -135.0),      # 오른쪽 눈 오른쪽 구석\n",
    "    (-150.0, -150.0, -125.0),    # 왼쪽 입 구석\n",
    "    (150.0, -150.0, -125.0)      # 오른쪽 입 구석\n",
    "])\n",
    "\n",
    "def get_euler_angles(rotation_vector):\n",
    "    \"\"\"회전 벡터를 오일러 각도로 변환\"\"\"\n",
    "    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "    euler_angles = cv2.decomposeProjectionMatrix(np.hstack((rotation_matrix, np.zeros((3, 1)))))[6]\n",
    "    return [math.radians(angle) for angle in euler_angles]\n",
    "\n",
    "def is_face_facing_camera(euler_angles):\n",
    "    \"\"\"얼굴이 카메라를 향하고 있는지 확인하는 함수\"\"\"\n",
    "    pitch, yaw, roll = euler_angles\n",
    "\n",
    "    # 각도 범위 조정 (단위: 라디안)\n",
    "    yaw_threshold = math.radians(20)\n",
    "    pitch_threshold = math.radians(20)\n",
    "    roll_threshold = math.radians(20)\n",
    "\n",
    "    is_facing = (abs(yaw) < yaw_threshold and \n",
    "                 abs(pitch) < pitch_threshold and \n",
    "                 abs(roll) < roll_threshold)\n",
    "\n",
    "    return is_facing, pitch, yaw, roll\n",
    "\n",
    "# 카메라 캡처\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # 카메라 행렬 정의\n",
    "    focal_length = width\n",
    "    center = (width / 2, height / 2)\n",
    "    camera_matrix = np.array(\n",
    "        [[focal_length, 0, center[0]],\n",
    "         [0, focal_length, center[1]],\n",
    "         [0, 0, 1]], dtype=\"double\"\n",
    "    )\n",
    "\n",
    "    # 이미지 전처리\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    face_detected = False\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.7:\n",
    "            face_detected = True\n",
    "            box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "            (x_min, y_min, x_max, y_max) = box.astype(\"int\")\n",
    "\n",
    "            # 2D 이미지 포인트 추출\n",
    "            image_points = np.array([\n",
    "                ((x_min + x_max) // 2, (y_min + y_max) // 2),  # 코끝\n",
    "                ((x_min + x_max) // 2, y_max),                 # 턱\n",
    "                (x_min, (y_min + y_max) // 2),                 # 왼쪽 눈\n",
    "                (x_max, (y_min + y_max) // 2),                 # 오른쪽 눈\n",
    "                (x_min, y_max - (y_max - y_min) // 3),         # 왼쪽 입\n",
    "                (x_max, y_max - (y_max - y_min) // 3)          # 오른쪽 입\n",
    "            ], dtype=\"double\")\n",
    "\n",
    "            # SolvePnP를 사용하여 회전 벡터와 변환 벡터 계산\n",
    "            dist_coeffs = np.zeros((4, 1))  # 카메라 왜곡 계수, 여기서는 0으로 가정\n",
    "            (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "            if success:\n",
    "                euler_angles = get_euler_angles(rotation_vector)\n",
    "                face_facing_camera, pitch, yaw, roll = is_face_facing_camera(euler_angles)\n",
    "                \n",
    "                if face_facing_camera:\n",
    "                    color = (0, 255, 0)  # 초록색 (정상)\n",
    "                    status = \"NORMAL\"\n",
    "                else:\n",
    "                    color = (0, 0, 255)  # 빨간색 (비정상)\n",
    "                    status = \"DANGER\"\n",
    "\n",
    "                # 얼굴 주변에 bounding box 그리기\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "                cv2.putText(frame, status, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "                # 얼굴 방향 정보 표시\n",
    "                cv2.putText(frame, f\"Pitch: {int(math.degrees(pitch))}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Yaw: {int(math.degrees(yaw))}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Roll: {int(math.degrees(roll))}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
